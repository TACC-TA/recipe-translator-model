{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import FastText,fasttext\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import math\n",
    "import re\n",
    "from string import digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "qc_embeding_path = './embeddings/lematized_embedding_v1.model'\n",
    "qc_embeddings = FastText.load(qc_embeding_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_embeding_path = './embeddings/cc.es.300.bin'\n",
    "es_embeddings = fasttext.load_facebook_vectors(es_embeding_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'de': 0,\n",
       " ',': 1,\n",
       " '.': 2,\n",
       " 'la': 3,\n",
       " 'y': 4,\n",
       " 'en': 5,\n",
       " 'que': 6,\n",
       " 'el': 7,\n",
       " '</s>': 8,\n",
       " 'a': 9,\n",
       " 'los': 10,\n",
       " ':': 11,\n",
       " '\"': 12,\n",
       " 'del': 13,\n",
       " 'un': 14,\n",
       " ')': 15,\n",
       " 'se': 16,\n",
       " 'con': 17,\n",
       " 'por': 18,\n",
       " 'las': 19,\n",
       " '(': 20,\n",
       " 'para': 21,\n",
       " 'una': 22,\n",
       " 'es': 23,\n",
       " 'no': 24,\n",
       " 'su': 25,\n",
       " 'al': 26,\n",
       " 'como': 27,\n",
       " 'lo': 28,\n",
       " '/': 29,\n",
       " 'más': 30,\n",
       " 'El': 31,\n",
       " 'o': 32,\n",
       " \"'\": 33,\n",
       " 'La': 34,\n",
       " '!': 35,\n",
       " '|': 36,\n",
       " '?': 37,\n",
       " 'me': 38,\n",
       " 'En': 39,\n",
       " '...': 40,\n",
       " '-': 41,\n",
       " 'sus': 42,\n",
       " 'este': 43,\n",
       " 'pero': 44,\n",
       " 'ha': 45,\n",
       " 'esta': 46,\n",
       " ';': 47,\n",
       " '“': 48,\n",
       " '_': 49,\n",
       " '”': 50,\n",
       " 'si': 51,\n",
       " 'sobre': 52,\n",
       " '¿': 53,\n",
       " 'fue': 54,\n",
       " 'son': 55,\n",
       " 'le': 56,\n",
       " 'muy': 57,\n",
       " 'ser': 58,\n",
       " 'ya': 59,\n",
       " 'tu': 60,\n",
       " 'todo': 61,\n",
       " '1': 62,\n",
       " 'entre': 63,\n",
       " 'te': 64,\n",
       " 'mi': 65,\n",
       " 'Los': 66,\n",
       " '%': 67,\n",
       " 'sin': 68,\n",
       " 'también': 69,\n",
       " 'está': 70,\n",
       " 'desde': 71,\n",
       " 'años': 72,\n",
       " 'puede': 73,\n",
       " 'dos': 74,\n",
       " '2': 75,\n",
       " 'cuando': 76,\n",
       " 'hasta': 77,\n",
       " 'nos': 78,\n",
       " 'tiene': 79,\n",
       " 'todos': 80,\n",
       " 'A': 81,\n",
       " 'No': 82,\n",
       " 'Y': 83,\n",
       " 'donde': 84,\n",
       " 'parte': 85,\n",
       " '3': 86,\n",
       " 'hay': 87,\n",
       " 'vez': 88,\n",
       " 'han': 89,\n",
       " 'e': 90,\n",
       " 'porque': 91,\n",
       " '#': 92,\n",
       " '…': 93,\n",
       " 'año': 94,\n",
       " '¡': 95,\n",
       " 'Se': 96,\n",
       " 'bien': 97,\n",
       " 'tiempo': 98,\n",
       " 'así': 99,\n",
       " 'cada': 100,\n",
       " 'uno': 101,\n",
       " 'DE': 102,\n",
       " 'hacer': 103,\n",
       " 'Por': 104,\n",
       " '»': 105,\n",
       " 'era': 106,\n",
       " 'forma': 107,\n",
       " 'Las': 108,\n",
       " 'hace': 109,\n",
       " 'vida': 110,\n",
       " 'mismo': 111,\n",
       " 'día': 112,\n",
       " '10': 113,\n",
       " 'Es': 114,\n",
       " 'otros': 115,\n",
       " 'mejor': 116,\n",
       " '4': 117,\n",
       " 'ver': 118,\n",
       " '*': 119,\n",
       " '5': 120,\n",
       " 'De': 121,\n",
       " '–': 122,\n",
       " 'sido': 123,\n",
       " 'gran': 124,\n",
       " 'durante': 125,\n",
       " 'mucho': 126,\n",
       " 'mundo': 127,\n",
       " 'Si': 128,\n",
       " 'ni': 129,\n",
       " 'personas': 130,\n",
       " 'tanto': 131,\n",
       " 'Para': 132,\n",
       " 'yo': 133,\n",
       " 'siempre': 134,\n",
       " 'solo': 135,\n",
       " 'ese': 136,\n",
       " 'eso': 137,\n",
       " 'lugar': 138,\n",
       " 'otro': 139,\n",
       " 'menos': 140,\n",
       " 'información': 141,\n",
       " 'poco': 142,\n",
       " 'nuevo': 143,\n",
       " 'había': 144,\n",
       " 'Más': 145,\n",
       " 'Un': 146,\n",
       " 'algo': 147,\n",
       " 'primera': 148,\n",
       " 'qué': 149,\n",
       " 'están': 150,\n",
       " 'después': 151,\n",
       " 'trabajo': 152,\n",
       " 'cuenta': 153,\n",
       " '12': 154,\n",
       " 'todas': 155,\n",
       " 'tan': 156,\n",
       " 'mayor': 157,\n",
       " 'ciudad': 158,\n",
       " 'estos': 159,\n",
       " '2017': 160,\n",
       " 'les': 161,\n",
       " '«': 162,\n",
       " 'cual': 163,\n",
       " 'esto': 164,\n",
       " 'he': 165,\n",
       " 'sólo': 166,\n",
       " 'aunque': 167,\n",
       " 'contra': 168,\n",
       " 'San': 169,\n",
       " ']': 170,\n",
       " 'pueden': 171,\n",
       " '[': 172,\n",
       " 'tres': 173,\n",
       " 'días': 174,\n",
       " 'caso': 175,\n",
       " 'otra': 176,\n",
       " 'antes': 177,\n",
       " '6': 178,\n",
       " '$': 179,\n",
       " 'sea': 180,\n",
       " '20': 181,\n",
       " 'tener': 182,\n",
       " 'primer': 183,\n",
       " 'España': 184,\n",
       " 'mas': 185,\n",
       " 'momento': 186,\n",
       " 'ahora': 187,\n",
       " '€': 188,\n",
       " 'otras': 189,\n",
       " '11': 190,\n",
       " '2016': 191,\n",
       " 'nada': 192,\n",
       " 'Pero': 193,\n",
       " 'unos': 194,\n",
       " '15': 195,\n",
       " 'esa': 196,\n",
       " 'casa': 197,\n",
       " '+': 198,\n",
       " '>': 199,\n",
       " 'hecho': 200,\n",
       " 'tipo': 201,\n",
       " 'nombre': 202,\n",
       " 'ellos': 203,\n",
       " '2015': 204,\n",
       " 'Este': 205,\n",
       " 'él': 206,\n",
       " '2012': 207,\n",
       " 'tienen': 208,\n",
       " '7': 209,\n",
       " '0': 210,\n",
       " '2013': 211,\n",
       " '8': 212,\n",
       " 'toda': 213,\n",
       " 'quien': 214,\n",
       " 'país': 215,\n",
       " 'poder': 216,\n",
       " 'cualquier': 217,\n",
       " 'nuestro': 218,\n",
       " 'historia': 219,\n",
       " 'Una': 220,\n",
       " 'of': 221,\n",
       " 'manera': 222,\n",
       " 'Esta': 223,\n",
       " '&': 224,\n",
       " 'cosas': 225,\n",
       " '2014': 226,\n",
       " 'ella': 227,\n",
       " 'nueva': 228,\n",
       " 'hoy': 229,\n",
       " 'decir': 230,\n",
       " 'The': 231,\n",
       " 'nuestra': 232,\n",
       " 'Ahora': 233,\n",
       " 'va': 234,\n",
       " '30': 235,\n",
       " '2011': 236,\n",
       " '2010': 237,\n",
       " 'detalles': 238,\n",
       " 'través': 239,\n",
       " 'sistema': 240,\n",
       " 'estas': 241,\n",
       " 'fueron': 242,\n",
       " 'hacia': 243,\n",
       " 'estado': 244,\n",
       " 'veces': 245,\n",
       " 'sino': 246,\n",
       " '16': 247,\n",
       " 'algunos': 248,\n",
       " 'debe': 249,\n",
       " 'muchos': 250,\n",
       " 'Me': 251,\n",
       " 'Con': 252,\n",
       " 'estaba': 253,\n",
       " '—': 254,\n",
       " 'aquí': 255,\n",
       " 'estar': 256,\n",
       " 'equipo': 257,\n",
       " 'Qué': 258,\n",
       " 'además': 259,\n",
       " 'final': 260,\n",
       " '9': 261,\n",
       " '13': 262,\n",
       " 'bajo': 263,\n",
       " 'grupo': 264,\n",
       " '18': 265,\n",
       " '14': 266,\n",
       " 's': 267,\n",
       " 'Su': 268,\n",
       " 'mientras': 269,\n",
       " 'fin': 270,\n",
       " 'Lo': 271,\n",
       " '@': 272,\n",
       " 'medio': 273,\n",
       " 'gracias': 274,\n",
       " 'uso': 275,\n",
       " 'Al': 276,\n",
       " '17': 277,\n",
       " 'agua': 278,\n",
       " 'datos': 279,\n",
       " 'sí': 280,\n",
       " 'opinión': 281,\n",
       " 'familia': 282,\n",
       " 'web': 283,\n",
       " 'tus': 284,\n",
       " 'embargo': 285,\n",
       " 'dice': 286,\n",
       " 'Nacional': 287,\n",
       " 'tengo': 288,\n",
       " 'pues': 289,\n",
       " 'nivel': 290,\n",
       " 'dentro': 291,\n",
       " 'misma': 292,\n",
       " 'ante': 293,\n",
       " 'luego': 294,\n",
       " 'Madrid': 295,\n",
       " 'posible': 296,\n",
       " 'the': 297,\n",
       " 'general': 298,\n",
       " 'será': 299,\n",
       " 'mayo': 300,\n",
       " '}': 301,\n",
       " 'muchas': 302,\n",
       " 'importante': 303,\n",
       " '..': 304,\n",
       " 'según': 305,\n",
       " 'Sin': 306,\n",
       " 'gente': 307,\n",
       " 'encuentra': 308,\n",
       " '19': 309,\n",
       " '•': 310,\n",
       " '21': 311,\n",
       " 'mis': 312,\n",
       " 'da': 313,\n",
       " 'ejemplo': 314,\n",
       " 'libro': 315,\n",
       " '22': 316,\n",
       " 'Estados': 317,\n",
       " 'tras': 318,\n",
       " 'Como': 319,\n",
       " 'pasado': 320,\n",
       " 'Gracias': 321,\n",
       " 'Juan': 322,\n",
       " 'millones': 323,\n",
       " 'dijo': 324,\n",
       " 'casi': 325,\n",
       " 'km': 326,\n",
       " 'punto': 327,\n",
       " '\\xad': 328,\n",
       " '2009': 329,\n",
       " 'español': 330,\n",
       " 'México': 331,\n",
       " 'junto': 332,\n",
       " 'juego': 333,\n",
       " 'empresa': 334,\n",
       " 'número': 335,\n",
       " 'niños': 336,\n",
       " '24': 337,\n",
       " 'diferentes': 338,\n",
       " 'horas': 339,\n",
       " 'nuestros': 340,\n",
       " 'También': 341,\n",
       " 'parece': 342,\n",
       " 'grandes': 343,\n",
       " '23': 344,\n",
       " '25': 345,\n",
       " 'serie': 346,\n",
       " 'zona': 347,\n",
       " '=': 348,\n",
       " 'persona': 349,\n",
       " 'tal': 350,\n",
       " 'cómo': 351,\n",
       " 'José': 352,\n",
       " 'servicio': 353,\n",
       " '00': 354,\n",
       " 'buena': 355,\n",
       " 'eran': 356,\n",
       " 'Universidad': 357,\n",
       " 'nunca': 358,\n",
       " 'LA': 359,\n",
       " 'Ver': 360,\n",
       " 'verdad': 361,\n",
       " 'Unidos': 362,\n",
       " 'entonces': 363,\n",
       " 'productos': 364,\n",
       " 'lado': 365,\n",
       " 'desarrollo': 366,\n",
       " 'hombre': 367,\n",
       " 'marzo': 368,\n",
       " 'mejores': 369,\n",
       " 'servicios': 370,\n",
       " '’': 371,\n",
       " 'semana': 372,\n",
       " '2008': 373,\n",
       " 'os': 374,\n",
       " 'población': 375,\n",
       " 'siendo': 376,\n",
       " 'centro': 377,\n",
       " 'tema': 378,\n",
       " 'Cuando': 379,\n",
       " 'haber': 380,\n",
       " 'meses': 381,\n",
       " 'varios': 382,\n",
       " 'Jugar': 383,\n",
       " 'Dios': 384,\n",
       " 'siglo': 385,\n",
       " 'abril': 386,\n",
       " 'siguiente': 387,\n",
       " 'diciembre': 388,\n",
       " 'ello': 389,\n",
       " 'gobierno': 390,\n",
       " 'partir': 391,\n",
       " 'proceso': 392,\n",
       " 'fuera': 393,\n",
       " 'proyecto': 394,\n",
       " 'enero': 395,\n",
       " 'obra': 396,\n",
       " 'cuatro': 397,\n",
       " 'octubre': 398,\n",
       " 'calidad': 399,\n",
       " 'Estado': 400,\n",
       " 'acuerdo': 401,\n",
       " 'algunas': 402,\n",
       " 'Además': 403,\n",
       " 'tenía': 404,\n",
       " 'artículo': 405,\n",
       " 'unas': 406,\n",
       " 'dar': 407,\n",
       " 'puedes': 408,\n",
       " 'and': 409,\n",
       " 'inglés': 410,\n",
       " 'septiembre': 411,\n",
       " 'total': 412,\n",
       " 'noviembre': 413,\n",
       " 'junio': 414,\n",
       " 'aún': 415,\n",
       " 'blog': 416,\n",
       " 'http': 417,\n",
       " 'último': 418,\n",
       " 'nosotros': 419,\n",
       " 'creo': 420,\n",
       " 'alguna': 421,\n",
       " 'noche': 422,\n",
       " 'buen': 423,\n",
       " 'política': 424,\n",
       " 'cambio': 425,\n",
       " 'programa': 426,\n",
       " 'sitio': 427,\n",
       " 'social': 428,\n",
       " 'película': 429,\n",
       " 'febrero': 430,\n",
       " 'julio': 431,\n",
       " 'mujer': 432,\n",
       " 'precio': 433,\n",
       " 'personal': 434,\n",
       " 'igual': 435,\n",
       " 'largo': 436,\n",
       " 'experiencia': 437,\n",
       " 'página': 438,\n",
       " '2007': 439,\n",
       " 'hizo': 440,\n",
       " 'segundo': 441,\n",
       " 'amor': 442,\n",
       " 'gusta': 443,\n",
       " 'estoy': 444,\n",
       " 'incluso': 445,\n",
       " 'mediante': 446,\n",
       " 'mujeres': 447,\n",
       " 'partido': 448,\n",
       " 'pueblo': 449,\n",
       " 'saber': 450,\n",
       " 'frente': 451,\n",
       " 'relación': 452,\n",
       " 'cerca': 453,\n",
       " 'ir': 454,\n",
       " 'problemas': 455,\n",
       " 'base': 456,\n",
       " 'cuerpo': 457,\n",
       " 'color': 458,\n",
       " 'paso': 459,\n",
       " 'Yo': 460,\n",
       " 'llegar': 461,\n",
       " 'presidente': 462,\n",
       " 'cantidad': 463,\n",
       " '°': 464,\n",
       " 'encontrar': 465,\n",
       " 'tarde': 466,\n",
       " 'n': 467,\n",
       " 'problema': 468,\n",
       " 'segunda': 469,\n",
       " 'Desde': 470,\n",
       " 'hora': 471,\n",
       " 'imagen': 472,\n",
       " 'agosto': 473,\n",
       " 'seguridad': 474,\n",
       " 'principal': 475,\n",
       " 'original': 476,\n",
       " 'bueno': 477,\n",
       " '·': 478,\n",
       " 'realidad': 479,\n",
       " 'minutos': 480,\n",
       " 'mes': 481,\n",
       " 'I': 482,\n",
       " 'fotos': 483,\n",
       " 'María': 484,\n",
       " 'línea': 485,\n",
       " 'producto': 486,\n",
       " 'empresas': 487,\n",
       " 'trata': 488,\n",
       " '26': 489,\n",
       " 'Santa': 490,\n",
       " 'Así': 491,\n",
       " '100': 492,\n",
       " 'soy': 493,\n",
       " 'mayoría': 494,\n",
       " 'primero': 495,\n",
       " 'Categoría': 496,\n",
       " '28': 497,\n",
       " 'música': 498,\n",
       " 'tenemos': 499,\n",
       " 'países': 500,\n",
       " 'Que': 501,\n",
       " 'muerte': 502,\n",
       " '<': 503,\n",
       " 'modo': 504,\n",
       " 'viaje': 505,\n",
       " 'mal': 506,\n",
       " '27': 507,\n",
       " 'hemos': 508,\n",
       " 'Argentina': 509,\n",
       " 'algún': 510,\n",
       " 'público': 511,\n",
       " 'puesto': 512,\n",
       " 'temporada': 513,\n",
       " 'mano': 514,\n",
       " 'varias': 515,\n",
       " 'puntos': 516,\n",
       " 'situación': 517,\n",
       " 'Carlos': 518,\n",
       " 'ayuda': 519,\n",
       " 'falta': 520,\n",
       " 'estudio': 521,\n",
       " 'podría': 522,\n",
       " 'in': 523,\n",
       " 'nuevos': 524,\n",
       " '2006': 525,\n",
       " 'derechos': 526,\n",
       " 'esos': 527,\n",
       " '50': 528,\n",
       " 'idea': 529,\n",
       " 'gratis': 530,\n",
       " 'tuvo': 531,\n",
       " 'espacio': 532,\n",
       " 'hijo': 533,\n",
       " 'sentido': 534,\n",
       " 'van': 535,\n",
       " 'realizar': 536,\n",
       " 'dicho': 537,\n",
       " 'Hay': 538,\n",
       " 'podemos': 539,\n",
       " 'derecho': 540,\n",
       " '29': 541,\n",
       " 'Fue': 542,\n",
       " 'entrada': 543,\n",
       " 'opiniones': 544,\n",
       " 'nacional': 545,\n",
       " 'nuevas': 546,\n",
       " 'precios': 547,\n",
       " 'Luis': 548,\n",
       " '....': 549,\n",
       " 'debido': 550,\n",
       " 'bastante': 551,\n",
       " 'fecha': 552,\n",
       " 'General': 553,\n",
       " 'favor': 554,\n",
       " 'cierto': 555,\n",
       " 'actual': 556,\n",
       " 'cosa': 557,\n",
       " 'especial': 558,\n",
       " 'atención': 559,\n",
       " 'mercado': 560,\n",
       " 'm': 561,\n",
       " 'lista': 562,\n",
       " 'hombres': 563,\n",
       " 'cuanto': 564,\n",
       " 'última': 565,\n",
       " 'juegos': 566,\n",
       " 'madre': 567,\n",
       " 'medios': 568,\n",
       " 'padre': 569,\n",
       " 'permite': 570,\n",
       " 'REDIRECCIÓN': 571,\n",
       " 'propio': 572,\n",
       " 'estilo': 573,\n",
       " 'palabras': 574,\n",
       " 'actividades': 575,\n",
       " 'EN': 576,\n",
       " 'anterior': 577,\n",
       " 'Gobierno': 578,\n",
       " 'Nueva': 579,\n",
       " 'único': 580,\n",
       " 'tierra': 581,\n",
       " 'pesar': 582,\n",
       " 'sociales': 583,\n",
       " 'sería': 584,\n",
       " 'sociedad': 585,\n",
       " 'tienes': 586,\n",
       " 'cinco': 587,\n",
       " 'resultados': 588,\n",
       " 'conocer': 589,\n",
       " 'EL': 590,\n",
       " 'control': 591,\n",
       " 'dinero': 592,\n",
       " 'guerra': 593,\n",
       " 'alguien': 594,\n",
       " 'Cómo': 595,\n",
       " 'luz': 596,\n",
       " 'hacen': 597,\n",
       " 'UTC': 598,\n",
       " '80': 599,\n",
       " 'claro': 600,\n",
       " 'salud': 601,\n",
       " 'dirección': 602,\n",
       " 'seguir': 603,\n",
       " 'producción': 604,\n",
       " 'versión': 605,\n",
       " 'haya': 606,\n",
       " '05': 607,\n",
       " 'alta': 608,\n",
       " '‘': 609,\n",
       " 'Ya': 610,\n",
       " 'ellas': 611,\n",
       " 'Esto': 612,\n",
       " 'obras': 613,\n",
       " 'hotel': 614,\n",
       " 'usuarios': 615,\n",
       " 'demás': 616,\n",
       " 'objetivo': 617,\n",
       " 'etc.': 618,\n",
       " 'temas': 619,\n",
       " 'q': 620,\n",
       " 'casos': 621,\n",
       " 'cuales': 622,\n",
       " 'edad': 623,\n",
       " 'papel': 624,\n",
       " 'condiciones': 625,\n",
       " 'Re': 626,\n",
       " 'Según': 627,\n",
       " 'quiere': 628,\n",
       " 'quiero': 629,\n",
       " 'actividad': 630,\n",
       " 'amigos': 631,\n",
       " 'quienes': 632,\n",
       " 'libre': 633,\n",
       " 'Barcelona': 634,\n",
       " 'respuesta': 635,\n",
       " 'puedo': 636,\n",
       " 'camino': 637,\n",
       " 'Mayo': 638,\n",
       " 'valor': 639,\n",
       " 'modelo': 640,\n",
       " 'hijos': 641,\n",
       " 'Te': 642,\n",
       " 'pasar': 643,\n",
       " 'oficial': 644,\n",
       " 'grande': 645,\n",
       " 'comentarios': 646,\n",
       " 'visto': 647,\n",
       " 'propia': 648,\n",
       " 'Juegos': 649,\n",
       " 'resultado': 650,\n",
       " 'nadie': 651,\n",
       " 'Centro': 652,\n",
       " 'respecto': 653,\n",
       " 'II': 654,\n",
       " '01': 655,\n",
       " 'libros': 656,\n",
       " 'campo': 657,\n",
       " 'ningún': 658,\n",
       " 'Europa': 659,\n",
       " 'traducción': 660,\n",
       " 'últimos': 661,\n",
       " 'acceso': 662,\n",
       " 'mí': 663,\n",
       " 'diseño': 664,\n",
       " 'resto': 665,\n",
       " 'primeros': 666,\n",
       " 'título': 667,\n",
       " 'haciendo': 668,\n",
       " 'estamos': 669,\n",
       " 'mil': 670,\n",
       " 'sigue': 671,\n",
       " 'vista': 672,\n",
       " 'Hola': 673,\n",
       " 'siguientes': 674,\n",
       " '2005': 675,\n",
       " 'Todos': 676,\n",
       " '²': 677,\n",
       " 'usted': 678,\n",
       " 'carrera': 679,\n",
       " '40': 680,\n",
       " 'municipio': 681,\n",
       " 'to': 682,\n",
       " 'banda': 683,\n",
       " 'época': 684,\n",
       " 'muestra': 685,\n",
       " 'necesario': 686,\n",
       " 'O': 687,\n",
       " 'Nuevo': 688,\n",
       " 'alto': 689,\n",
       " 'C': 690,\n",
       " 'seguro': 691,\n",
       " 'queda': 692,\n",
       " 'región': 693,\n",
       " 'aire': 694,\n",
       " 'mañana': 695,\n",
       " 'Chile': 696,\n",
       " 'mar': 697,\n",
       " 'inscripción': 698,\n",
       " 'capacidad': 699,\n",
       " 'red': 700,\n",
       " 'dado': 701,\n",
       " 'presente': 702,\n",
       " 'allí': 703,\n",
       " 'deben': 704,\n",
       " 'ahí': 705,\n",
       " 'ofrece': 706,\n",
       " '31': 707,\n",
       " 'crear': 708,\n",
       " 'interés': 709,\n",
       " 'Mi': 710,\n",
       " 'duda': 711,\n",
       " 'esas': 712,\n",
       " 'principales': 713,\n",
       " 'voy': 714,\n",
       " 'poner': 715,\n",
       " 'pasa': 716,\n",
       " 'artículos': 717,\n",
       " 'manos': 718,\n",
       " 'provincia': 719,\n",
       " 'ley': 720,\n",
       " 'capital': 721,\n",
       " 'sector': 722,\n",
       " 'pueda': 723,\n",
       " '\\\\': 724,\n",
       " 'dejar': 725,\n",
       " 'edición': 726,\n",
       " 'leer': 727,\n",
       " 'interior': 728,\n",
       " 'usuario': 729,\n",
       " 'orden': 730,\n",
       " 'cabo': 731,\n",
       " 'grupos': 732,\n",
       " 'contenido': 733,\n",
       " 'importantes': 734,\n",
       " 'cabeza': 735,\n",
       " 'Después': 736,\n",
       " 'Antonio': 737,\n",
       " 'lleva': 738,\n",
       " 'fácil': 739,\n",
       " 'conocido': 740,\n",
       " 'construcción': 741,\n",
       " 'correo': 742,\n",
       " 'autor': 743,\n",
       " 'éxito': 744,\n",
       " 'dio': 745,\n",
       " 'llamado': 746,\n",
       " 'nuestras': 747,\n",
       " 'Ley': 748,\n",
       " 'Francisco': 749,\n",
       " 'Información': 750,\n",
       " 'investigación': 751,\n",
       " 'calle': 752,\n",
       " 'Buenos': 753,\n",
       " 'principio': 754,\n",
       " 'Durante': 755,\n",
       " 'miembros': 756,\n",
       " 'futuro': 757,\n",
       " 'Real': 758,\n",
       " 'metros': 759,\n",
       " 'pequeño': 760,\n",
       " 'Internacional': 761,\n",
       " 'comunidad': 762,\n",
       " 'obtener': 763,\n",
       " 'Aunque': 764,\n",
       " 'apoyo': 765,\n",
       " 'marca': 766,\n",
       " 'fuerte': 767,\n",
       " 'clase': 768,\n",
       " 'foro': 769,\n",
       " 'internacional': 770,\n",
       " 'fuerza': 771,\n",
       " 'Internet': 772,\n",
       " 'amigo': 773,\n",
       " 'director': 774,\n",
       " 'ninguna': 775,\n",
       " 'recursos': 776,\n",
       " 'conjunto': 777,\n",
       " 'Entre': 778,\n",
       " 'todavía': 779,\n",
       " 'media': 780,\n",
       " 'arte': 781,\n",
       " 'medida': 782,\n",
       " 'imágenes': 783,\n",
       " 'has': 784,\n",
       " 'joven': 785,\n",
       " 'Google': 786,\n",
       " 'sé': 787,\n",
       " 'sabe': 788,\n",
       " 'formación': 789,\n",
       " 'ambos': 790,\n",
       " 'comunicación': 791,\n",
       " 'local': 792,\n",
       " 'viajeros': 793,\n",
       " 'real': 794,\n",
       " 'DEL': 795,\n",
       " 'u': 796,\n",
       " 'educación': 797,\n",
       " 'pm': 798,\n",
       " 'estudios': 799,\n",
       " 'habitantes': 800,\n",
       " 'acción': 801,\n",
       " 'Gran': 802,\n",
       " 'área': 803,\n",
       " 'discusión': 804,\n",
       " 'habían': 805,\n",
       " 'República': 806,\n",
       " 'cargo': 807,\n",
       " 'origen': 808,\n",
       " 'Ciudad': 809,\n",
       " 'ojos': 810,\n",
       " 'álbum': 811,\n",
       " 'venta': 812,\n",
       " 'natural': 813,\n",
       " 'existe': 814,\n",
       " 'sur': 815,\n",
       " 'superior': 816,\n",
       " 'elementos': 817,\n",
       " 'tomar': 818,\n",
       " 'Todo': 819,\n",
       " 'América': 820,\n",
       " 'Francia': 821,\n",
       " 've': 822,\n",
       " 'compartir': 823,\n",
       " 'ti': 824,\n",
       " 'mucha': 825,\n",
       " 'x': 826,\n",
       " '2000': 827,\n",
       " 'd': 828,\n",
       " 'corazón': 829,\n",
       " 'especie': 830,\n",
       " 'encuentran': 831,\n",
       " 'viene': 832,\n",
       " 'Mundial': 833,\n",
       " 'razón': 834,\n",
       " 'hablar': 835,\n",
       " 'Pedro': 836,\n",
       " 'aquellos': 837,\n",
       " 'energía': 838,\n",
       " 'Responder': 839,\n",
       " 'canción': 840,\n",
       " '09': 841,\n",
       " 'partes': 842,\n",
       " 'llevar': 843,\n",
       " 'tenido': 844,\n",
       " 'mejorar': 845,\n",
       " 'trabajar': 846,\n",
       " 'menor': 847,\n",
       " 'profesional': 848,\n",
       " '06': 849,\n",
       " 'río': 850,\n",
       " 'escribió': 851,\n",
       " 'vamos': 852,\n",
       " 'Aires': 853,\n",
       " 'especialmente': 854,\n",
       " 'equipos': 855,\n",
       " 'norte': 856,\n",
       " 'Publicado': 857,\n",
       " 'padres': 858,\n",
       " '04': 859,\n",
       " 'Hoy': 860,\n",
       " 'comentario': 861,\n",
       " 'organización': 862,\n",
       " 'Archivo': 863,\n",
       " 'Jesús': 864,\n",
       " '2004': 865,\n",
       " '{': 866,\n",
       " 'superficie': 867,\n",
       " 'completo': 868,\n",
       " 'aplicación': 869,\n",
       " 'movimiento': 870,\n",
       " 'clic': 871,\n",
       " 'realmente': 872,\n",
       " 'texto': 873,\n",
       " 'contacto': 874,\n",
       " 'gestión': 875,\n",
       " 'cocina': 876,\n",
       " 'euros': 877,\n",
       " 'voz': 878,\n",
       " 'Manuel': 879,\n",
       " 'Hotel': 880,\n",
       " 'única': 881,\n",
       " 'sean': 882,\n",
       " '02': 883,\n",
       " 'cara': 884,\n",
       " 'usar': 885,\n",
       " 'presencia': 886,\n",
       " 'disco': 887,\n",
       " 'jugar': 888,\n",
       " 'niño': 889,\n",
       " 'video': 890,\n",
       " '©': 891,\n",
       " '03': 892,\n",
       " 'cine': 893,\n",
       " 'material': 894,\n",
       " 'función': 895,\n",
       " 'cultura': 896,\n",
       " 'Miguel': 897,\n",
       " 'Mar': 898,\n",
       " 'palabra': 899,\n",
       " 'común': 900,\n",
       " 'evitar': 901,\n",
       " 'compañía': 902,\n",
       " 'Casa': 903,\n",
       " '�': 904,\n",
       " 'alrededor': 905,\n",
       " 'Colombia': 906,\n",
       " 'personajes': 907,\n",
       " 'proyectos': 908,\n",
       " 'acerca': 909,\n",
       " 'posición': 910,\n",
       " 'B': 911,\n",
       " 'formas': 912,\n",
       " '08': 913,\n",
       " 'mismos': 914,\n",
       " 'televisión': 915,\n",
       " 'llegó': 916,\n",
       " 'salir': 917,\n",
       " 'jóvenes': 918,\n",
       " 'electrónico': 919,\n",
       " 'momentos': 920,\n",
       " '^': 921,\n",
       " 'Facebook': 922,\n",
       " 'cambios': 923,\n",
       " 'Tras': 924,\n",
       " 'curso': 925,\n",
       " 'seis': 926,\n",
       " 'Iglesia': 927,\n",
       " 'Guerra': 928,\n",
       " 'clientes': 929,\n",
       " 'estaban': 930,\n",
       " 'pequeña': 931,\n",
       " 'político': 932,\n",
       " 'estadounidense': 933,\n",
       " 'vivir': 934,\n",
       " 'necesidad': 935,\n",
       " 'Le': 936,\n",
       " 'conocimiento': 937,\n",
       " 'oportunidad': 938,\n",
       " 'partidos': 939,\n",
       " 'Santiago': 940,\n",
       " 'presenta': 941,\n",
       " 'Educación': 942,\n",
       " 'causa': 943,\n",
       " 'demasiado': 944,\n",
       " 'cambiar': 945,\n",
       " 'Venezuela': 946,\n",
       " 'pregunta': 947,\n",
       " 'género': 948,\n",
       " 'sistemas': 949,\n",
       " 'encuentro': 950,\n",
       " 'llega': 951,\n",
       " 'perfecta': 952,\n",
       " 'utilizar': 953,\n",
       " 'diferencia': 954,\n",
       " '07': 955,\n",
       " 'características': 956,\n",
       " 'establecimiento': 957,\n",
       " 'piel': 958,\n",
       " 'lugares': 959,\n",
       " 'efecto': 960,\n",
       " 'tampoco': 961,\n",
       " 'difícil': 962,\n",
       " 'tamaño': 963,\n",
       " 'consejos': 964,\n",
       " 'tú': 965,\n",
       " 'mensaje': 966,\n",
       " 'hacerlo': 967,\n",
       " 'importancia': 968,\n",
       " 'negocio': 969,\n",
       " 'baja': 970,\n",
       " 'posibilidad': 971,\n",
       " 'Club': 972,\n",
       " 'deja': 973,\n",
       " 'foto': 974,\n",
       " 'éste': 975,\n",
       " 'tratamiento': 976,\n",
       " 'libertad': 977,\n",
       " 'somos': 978,\n",
       " 'conseguir': 979,\n",
       " 'habitaciones': 980,\n",
       " 'Servicios': 981,\n",
       " 'fútbol': 982,\n",
       " 'humanos': 983,\n",
       " 'fondo': 984,\n",
       " 'pensar': 985,\n",
       " '60': 986,\n",
       " 'ideas': 987,\n",
       " 'comprar': 988,\n",
       " '2003': 989,\n",
       " 'York': 990,\n",
       " 'análisis': 991,\n",
       " 'Instituto': 992,\n",
       " 'participación': 993,\n",
       " 'Estamos': 994,\n",
       " 'blanco': 995,\n",
       " 'prueba': 996,\n",
       " 'categoría': 997,\n",
       " 'volver': 998,\n",
       " 'rey': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_embeddings.key_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quechua</th>\n",
       "      <th>spanish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ch’arwi</td>\n",
       "      <td>Desorden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Runa</td>\n",
       "      <td>Persona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chanin</td>\n",
       "      <td>Precio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Puka</td>\n",
       "      <td>Rojo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hallp’a</td>\n",
       "      <td>Tierra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2066</th>\n",
       "      <td>Runakuna manan mallkikunata tarpunkuchu chaymi...</td>\n",
       "      <td>La personas no plantan árboles es uno de los f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2067</th>\n",
       "      <td>Erqe mamanpa wañusqanmanta waqan.</td>\n",
       "      <td>El niño llora porque su madre murió.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068</th>\n",
       "      <td>Huk wayna chakamanta wukchuyukusqa hinaspa wañ...</td>\n",
       "      <td>Un joven se lanzó del puente y murió.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2069</th>\n",
       "      <td>Mama churin mana wasinman kutimusqanmanta waqan.</td>\n",
       "      <td>La madre llora porque su hijo no vuelve a la c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070</th>\n",
       "      <td>Erqe anchata karru alqonta saruruqtin waqasqa.</td>\n",
       "      <td>El niño lloró mucho porque el carro lo atropel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2071 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                quechua  \\\n",
       "0                                               Ch’arwi   \n",
       "1                                                  Runa   \n",
       "2                                                Chanin   \n",
       "3                                                  Puka   \n",
       "4                                               Hallp’a   \n",
       "...                                                 ...   \n",
       "2066  Runakuna manan mallkikunata tarpunkuchu chaymi...   \n",
       "2067                  Erqe mamanpa wañusqanmanta waqan.   \n",
       "2068  Huk wayna chakamanta wukchuyukusqa hinaspa wañ...   \n",
       "2069   Mama churin mana wasinman kutimusqanmanta waqan.   \n",
       "2070     Erqe anchata karru alqonta saruruqtin waqasqa.   \n",
       "\n",
       "                                                spanish  \n",
       "0                                              Desorden  \n",
       "1                                               Persona  \n",
       "2                                                Precio  \n",
       "3                                                  Rojo  \n",
       "4                                                Tierra  \n",
       "...                                                 ...  \n",
       "2066  La personas no plantan árboles es uno de los f...  \n",
       "2067               El niño llora porque su madre murió.  \n",
       "2068              Un joven se lanzó del puente y murió.  \n",
       "2069  La madre llora porque su hijo no vuelve a la c...  \n",
       "2070  El niño lloró mucho porque el carro lo atropel...  \n",
       "\n",
       "[2071 rows x 2 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.DataFrame(columns=['quechua', 'spanish'])\n",
    "dataset['quechua'] = pd.read_csv('./train_data/QuechuaCollaoCorpus.csv')['Quechua']\n",
    "dataset['spanish'] = pd.read_csv('./train_data/QuechuaCollaoCorpus.csv')['Traducción']\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "quechua    2\n",
       "spanish    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.dropna(inplace=True)\n",
    "dataset.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_sentence(sentence):\n",
    "    num_digits = str.maketrans('', '', digits)\n",
    "\n",
    "    sentence = sentence.lower()\n",
    "    sentence = re.sub(\" +\", \" \", sentence)\n",
    "    sentence = re.sub(\" . \", \"\", sentence)\n",
    "    sentence = sentence.translate(num_digits)\n",
    "    sentence = sentence.strip()\n",
    "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence)\n",
    "    sentence = sentence.rstrip().strip()\n",
    "    \n",
    "    # Remove the final dot if it exists\n",
    "    if sentence.endswith('.'):\n",
    "        sentence = sentence[:-1].strip()\n",
    "    \n",
    "    sentence = 'start_ ' + sentence + ' _end'  # importante\n",
    "\n",
    "    return sentence\n",
    "\n",
    "def clean_df(df):\n",
    "    df['quechua'] = df['quechua'].apply(lambda x: preprocess_sentence(x))\n",
    "    df['spanish'] = df['spanish'].apply(lambda x: preprocess_sentence(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quechua</th>\n",
       "      <th>spanish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>start_ ch’arwi _end</td>\n",
       "      <td>start_ desorden _end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>start_ runa _end</td>\n",
       "      <td>start_ persona _end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>start_ chanin _end</td>\n",
       "      <td>start_ precio _end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>start_ puka _end</td>\n",
       "      <td>start_ rojo _end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>start_ hallp’a _end</td>\n",
       "      <td>start_ tierra _end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2064</th>\n",
       "      <td>start_ runakuna manan mallkikunata tarpunkuchu...</td>\n",
       "      <td>start_ la personas no plantan árboles es uno d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2065</th>\n",
       "      <td>start_ erqe mamanpa wañusqanmanta waqan _end</td>\n",
       "      <td>start_ el niño llora porque su madre murió _end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2066</th>\n",
       "      <td>start_ huk wayna chakamanta wukchuyukusqa hina...</td>\n",
       "      <td>start_ un joven se lanzó del puentemurió _end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2067</th>\n",
       "      <td>start_ mama churin mana wasinman kutimusqanman...</td>\n",
       "      <td>start_ la madre llora porque su hijo no vuelve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068</th>\n",
       "      <td>start_ erqe anchata karru alqonta saruruqtin w...</td>\n",
       "      <td>start_ el niño lloró mucho porque el carro lo ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2069 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                quechua  \\\n",
       "0                                   start_ ch’arwi _end   \n",
       "1                                      start_ runa _end   \n",
       "2                                    start_ chanin _end   \n",
       "3                                      start_ puka _end   \n",
       "4                                   start_ hallp’a _end   \n",
       "...                                                 ...   \n",
       "2064  start_ runakuna manan mallkikunata tarpunkuchu...   \n",
       "2065       start_ erqe mamanpa wañusqanmanta waqan _end   \n",
       "2066  start_ huk wayna chakamanta wukchuyukusqa hina...   \n",
       "2067  start_ mama churin mana wasinman kutimusqanman...   \n",
       "2068  start_ erqe anchata karru alqonta saruruqtin w...   \n",
       "\n",
       "                                                spanish  \n",
       "0                                  start_ desorden _end  \n",
       "1                                   start_ persona _end  \n",
       "2                                    start_ precio _end  \n",
       "3                                      start_ rojo _end  \n",
       "4                                    start_ tierra _end  \n",
       "...                                                 ...  \n",
       "2064  start_ la personas no plantan árboles es uno d...  \n",
       "2065    start_ el niño llora porque su madre murió _end  \n",
       "2066      start_ un joven se lanzó del puentemurió _end  \n",
       "2067  start_ la madre llora porque su hijo no vuelve...  \n",
       "2068  start_ el niño lloró mucho porque el carro lo ...  \n",
       "\n",
       "[2069 rows x 2 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m embeddings\u001b[38;5;241m.\u001b[39mbuild_vocab(dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquechua\u001b[39m\u001b[38;5;124m'\u001b[39m], update\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      2\u001b[0m embeddings\u001b[38;5;241m.\u001b[39mtrain(dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquechua\u001b[39m\u001b[38;5;124m'\u001b[39m], total_examples\u001b[38;5;241m=\u001b[39membeddings\u001b[38;5;241m.\u001b[39mcorpus_count, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m,)\n",
      "File \u001b[0;32m~/.conda/envs/tacc/lib/python3.12/site-packages/gensim/models/word2vec.py:491\u001b[0m, in \u001b[0;36mWord2Vec.build_vocab\u001b[0;34m(self, corpus_iterable, corpus_file, update, progress_per, keep_raw_vocab, trim_rule, **kwargs)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Build vocabulary from a sequence of sentences (can be a once-only generator stream).\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \n\u001b[1;32m    455\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    488\u001b[0m \n\u001b[1;32m    489\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    490\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_corpus_sanity(corpus_iterable\u001b[38;5;241m=\u001b[39mcorpus_iterable, corpus_file\u001b[38;5;241m=\u001b[39mcorpus_file, passes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 491\u001b[0m total_words, corpus_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_vocab(\n\u001b[1;32m    492\u001b[0m     corpus_iterable\u001b[38;5;241m=\u001b[39mcorpus_iterable, corpus_file\u001b[38;5;241m=\u001b[39mcorpus_file, progress_per\u001b[38;5;241m=\u001b[39mprogress_per, trim_rule\u001b[38;5;241m=\u001b[39mtrim_rule)\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcorpus_count \u001b[38;5;241m=\u001b[39m corpus_count\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcorpus_total_words \u001b[38;5;241m=\u001b[39m total_words\n",
      "File \u001b[0;32m~/.conda/envs/tacc/lib/python3.12/site-packages/gensim/models/word2vec.py:586\u001b[0m, in \u001b[0;36mWord2Vec.scan_vocab\u001b[0;34m(self, corpus_iterable, corpus_file, progress_per, workers, trim_rule)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m corpus_file:\n\u001b[1;32m    584\u001b[0m     corpus_iterable \u001b[38;5;241m=\u001b[39m LineSentence(corpus_file)\n\u001b[0;32m--> 586\u001b[0m total_words, corpus_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_scan_vocab(corpus_iterable, progress_per, trim_rule)\n\u001b[1;32m    588\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    589\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcollected \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m word types from a corpus of \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m raw words and \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m sentences\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    590\u001b[0m     \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_vocab), total_words, corpus_count\n\u001b[1;32m    591\u001b[0m )\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m total_words, corpus_count\n",
      "File \u001b[0;32m~/.conda/envs/tacc/lib/python3.12/site-packages/gensim/models/word2vec.py:569\u001b[0m, in \u001b[0;36mWord2Vec._scan_vocab\u001b[0;34m(self, sentences, progress_per, trim_rule)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sentence_no \u001b[38;5;241m%\u001b[39m progress_per \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    565\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    566\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPROGRESS: at sentence #\u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m, processed \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m words, keeping \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m word types\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    567\u001b[0m         sentence_no, total_words, \u001b[38;5;28mlen\u001b[39m(vocab),\n\u001b[1;32m    568\u001b[0m     )\n\u001b[0;32m--> 569\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m sentence:\n\u001b[1;32m    570\u001b[0m     vocab[word] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    571\u001b[0m total_words \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(sentence)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object is not iterable"
     ]
    }
   ],
   "source": [
    "qc.build_vocab(dataset['quechua'], update=True)\n",
    "embeddings.train(dataset['quechua'], total_examples=embeddings.corpus_count, epochs=15,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    r\"\"\"Inject some information about the relative or absolute position of the tokens in the sequence.\n",
    "        The positional encodings have the same dimension as the embeddings, so that the two can be summed.\n",
    "        Here, we use sine and cosine functions of different frequencies.\n",
    "    .. math:\n",
    "        \\text{PosEncoder}(pos, 2i) = sin(pos/10000^(2i/d_model))\n",
    "        \\text{PosEncoder}(pos, 2i+1) = cos(pos/10000^(2i/d_model))\n",
    "        \\text{where pos is the word position and i is the embed idx)\n",
    "    Args:\n",
    "        d_model: the embed dim (required).\n",
    "        dropout: the dropout value (default=0.1).\n",
    "        max_len: the max. length of the incoming sequence (default=5000).\n",
    "    Examples:\n",
    "        >>> pos_encoder = PositionalEncoding(d_model)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        r\"\"\"Inputs of forward function\n",
    "        Args:\n",
    "            x: the sequence fed to the positional encoder model (required).\n",
    "        Shape:\n",
    "            x: [sequence length, batch size, embed dim]\n",
    "            output: [sequence length, batch size, embed dim]\n",
    "        Examples:\n",
    "            >>> output = pos_encoder(x)\n",
    "        \"\"\"\n",
    "\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Transformer):\n",
    "    \"\"\"Container module with an encoder, a recurrent or transformer module, and a decoder.\"\"\"\n",
    "\n",
    "    def __init__(self, ntoken, ninp, nhead, nhid, nlayers, dropout=0.5):\n",
    "        super(TransformerModel, self).__init__(d_model=ninp, nhead=nhead, dim_feedforward=nhid, num_encoder_layers=nlayers)\n",
    "        self.model_type = 'Transformer'\n",
    "        self.src_mask = None\n",
    "        self.pos_encoder = PositionalEncoding(ninp, dropout)\n",
    "\n",
    "        self.input_emb = nn.Embedding(ntoken, ninp)\n",
    "        self.ninp = ninp\n",
    "        self.decoder = nn.Linear(ninp, ntoken)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def _generate_square_subsequent_mask(self, sz):\n",
    "        return torch.log(torch.tril(torch.ones(sz,sz)))\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        nn.init.uniform_(self.input_emb.weight, -initrange, initrange)\n",
    "        nn.init.zeros_(self.decoder.bias)\n",
    "        nn.init.uniform_(self.decoder.weight, -initrange, initrange)\n",
    "\n",
    "    def forward(self, src, has_mask=True):\n",
    "        if has_mask:\n",
    "            device = src.device\n",
    "            if self.src_mask is None or self.src_mask.size(0) != len(src):\n",
    "                mask = self._generate_square_subsequent_mask(len(src)).to(device)\n",
    "                self.src_mask = mask\n",
    "        else:\n",
    "            self.src_mask = None\n",
    "\n",
    "        src = self.input_emb(src) * math.sqrt(self.ninp)\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.encoder(src, mask=self.src_mask)\n",
    "        output = self.decoder(output)\n",
    "        return F.log_softmax(output, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 32, 512])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pass embeding fasttext to embedding layer\n",
    "\n",
    "vectors  = torch.tensor(embeddings.wv.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2561, 50])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = torch.FloatTensor(vectors)\n",
    "embedding = nn.Embedding.from_pretrained(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.50889   ,  0.1686052 , -0.24421082,  0.15753326, -0.36160132,\n",
       "        0.24685092, -0.18002182, -0.17252123, -0.28220466,  0.38489878,\n",
       "       -0.02020847,  0.21663795,  0.05879577, -0.15637793,  0.24656545,\n",
       "       -0.24084774,  0.07427774,  0.5354595 ,  0.253039  , -0.18267351,\n",
       "        0.30777204,  0.32439196,  0.2406271 , -0.3227719 , -0.404154  ,\n",
       "       -0.41446486, -0.19660893,  0.13176258, -0.5842336 , -0.5161695 ,\n",
       "        0.72205323,  0.07310987,  0.3700086 , -0.09453848,  0.10423267,\n",
       "       -0.1513904 ,  0.5310659 ,  0.1339472 , -0.16158412, -0.44667733,\n",
       "       -0.12508145,  0.09292982, -0.06693438,  0.01572501,  0.17116961,\n",
       "       -0.12222562,  0.12246072,  0.12925214, -0.03877937, -0.1251332 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.wv['wasi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3116,  0.3042,  0.1542,  0.0290,  0.4287, -0.3780, -0.3416,  0.0329,\n",
       "         -0.3269,  0.1054, -0.0190,  0.2326, -0.0456,  0.2658, -0.1921,  0.3213,\n",
       "          0.3945,  0.3484,  0.2451, -0.3252, -0.2175,  0.2806,  0.1836, -0.1274,\n",
       "         -0.2662, -0.5361, -0.5020, -0.0786,  0.1853, -0.5092,  0.6678,  0.0465,\n",
       "         -0.3356,  0.2425,  0.1637, -0.1459, -0.2762, -0.0944,  0.0261,  0.0998,\n",
       "         -0.0642, -0.3979,  0.2708,  0.5895, -0.0360,  0.5141,  0.0692,  0.2658,\n",
       "          0.5971,  0.0239]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding(torch.LongTensor([0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tacc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
